{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch pour $h$ et $tailleBloc$ modèle NP\n",
    "\n",
    "\n",
    "\n",
    "    Implémentation du modèle Non-paramétrique \n",
    "\n",
    "    Plusieurs fonctions implémentées :\n",
    "        - `infos_blocs` : crée les blocs à partir de l'historique, et calcule moyenne, ... (évite de refaire le calcul à chaque fois)\n",
    "        - `previsions_NP_h_fixe` : réalise des prédictions pour un hyper paramètre h donné\n",
    "        - `rmse` : calcule l'erreur rmse (utilisé pour le choix de l'hyper-paramètre h)\n",
    "        - `meilleur_h` : choisit le meilleur paramètre h, comme moyenne des meilleurs paramètres qui auraient permis de prédire chacune des périodes qui sont aux mêmes dates que celle que l'on souhaite prédire, mais pour des années antérieures\n",
    "        - `previsions_NP` : fonction finale, qui réalise les prédictions souhaitées après avoir choisir le meilleur hyper paramètre h \n",
    "\n",
    "## Objectif : update avec gridsearch\n",
    "\n",
    "On va rajouter à la fonction `previsions_NP` une option `gridsearch` en plus de `meilleur_h` pour le choix des paramètres. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from datetime import timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infos_blocs (histoMod,tailleBlocs) :\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    histoMod : Historique du trafic sur lequel faire les blocs\n",
    "    tailleBlocs : taille des blocs à réaliser\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Blocs, Blocs_CR, LastBlocs_CR : Blocs, blocs centrés réduits et dernier bloc centré réduit\n",
    "    Stats : Moyennes et Ecarts-types de chacun des blocs\n",
    "    distances : distances entre chacun des blocs centrés réduits avec le dernier bloc centré réduit\n",
    "    \"\"\"\n",
    "    as_strided = np.lib.stride_tricks.as_strided\n",
    "    Blocs = pd.DataFrame(as_strided(histoMod[\"PAX\"], (len(histoMod[\"PAX\"])-(tailleBlocs-1) , tailleBlocs) , (histoMod[\"PAX\"].values.strides * 2)))   \n",
    "    Stats = pd.DataFrame()\n",
    "    Stats['Mean'] = Blocs.mean(axis=1)\n",
    "    Stats['Stds'] = Blocs.std(axis=1)\n",
    "    Blocs_CR = (Blocs - np.array(Stats['Mean']).reshape(-1,1)) / np.array(Stats['Stds']).reshape(-1,1)\n",
    "    LastBloc_CR = pd.DataFrame(np.array(Blocs_CR)[-1].reshape(1,-1))\n",
    "    # Calcul des distances entre chaque bloc (utilisées ensuite pour le calcul des poids) :\n",
    "    distances = np.sum((np.array(LastBloc_CR)-np.array(Blocs_CR[:-1]))**2,axis=1)\n",
    "    return (Blocs, Blocs_CR, LastBloc_CR, Stats, distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def previsions_NP_h_fixe (histoMod, Calendrier, dateFinMod, infosBlocs , hPrev, h, ic = 0, tailleBlocs = 365) :\n",
    "    \"\"\"\n",
    "    Fonction qui réalise les prédictions selon le modèle non-paramétrique\n",
    "    à partir de l'historique donné (déjà filtré pour un faisceau et un type de mouvement) \n",
    "    et des caractéristiques des blocs déjà calculées (pour éviter de le refaire à chaque fois dans l'appel de la fonction qui fait une cross-validation),\n",
    "    pour un hyper paramètre h donné.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    histoMod, Calendrier, dateFinMod, hPrev, tailleBlocs, ic : \n",
    "        idem que dans la fonction previsions_NP \n",
    "    infosBlocs : tuple\n",
    "        Contient toutes les infos des blocs déjà calculées : Blocs, Blocs_CR, LastBloc_CR, Stats, distances\n",
    "    h : int\n",
    "        hyper paramètre h / largeur de la fenêtre\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    PrevisionsNP : DataFrame\n",
    "        Prévisions journalières du modèle (contient 'PAX_NP', 'Date', 'Faisceau', 'ArrDep') \n",
    "        + intervalle de confiance 'ICic_low_NP' et 'ICic_up_NP' si ic != 0\n",
    "\n",
    "    \"\"\"\n",
    "    Blocs, Blocs_CR, LastBloc_CR, Stats, distances = infosBlocs\n",
    "    # Calcul des poids en comparant la similarité des motifs des blocs (noyau gaussien):      \n",
    "    weights = pd.DataFrame( (1/math.sqrt(2*math.pi)**tailleBlocs) * np.exp(- distances / (2*h)))\n",
    "    # Calcul des prévisions une par une : \n",
    "    PrevisionsNP = pd.DataFrame()\n",
    "    datePrev = dateFinMod\n",
    "    \n",
    "    for horizonPrev in range(1,hPrev+1) :         \n",
    "        datePrev += timedelta(days=1)\n",
    "        # Correction des poids en utilisant le calendrier :    \n",
    "        CalPrev = np.array(Calendrier[Calendrier['Date']==datePrev])\n",
    "        histoPrev = histoMod[tailleBlocs - 1 + horizonPrev : ]\n",
    "        indJourPrev = np.array(histoPrev[\"Pont_LunF\"]) == CalPrev[:,5]\n",
    "        colHistoPrev = [\"Pont_MarF\",\"Pont_Mer1F\",\"Pont_Mer2F\",\"Pont_JeuF\",\"Pont_VenF\",\"Vac_Toussaint\",\"Vac_Noel\",\"Vac_Hiver_A\",\"Vac_Hiver_B\",\"Vac_Hiver_C\",\"Vac_Printemps_A\",\"Vac_Printemps_B\",\"Vac_Printemps_C\",\"Vac_Ete\"]\n",
    "        indCalPrev = [6,7,8,9,10,13,14,15,16,17,18,19,20,21]\n",
    "        for k in range(len(indCalPrev)) :\n",
    "            indJourPrev = indJourPrev & (np.array(histoPrev[colHistoPrev[k]]) == CalPrev[:,indCalPrev[k]])\n",
    "        \n",
    "        # On ajoute une correction avec le jour de la semaine uniquement si cela n'annule pas tous les poids :\n",
    "        indJourPrev2 = indJourPrev & (np.array(histoPrev[\"JourSem\"]) == CalPrev[:,2])\n",
    "        if sum(indJourPrev2) != 0 :\n",
    "            indJourPrev = indJourPrev2\n",
    "\n",
    "        indJourPrev = indJourPrev.reshape(-1,1)\n",
    "        weightsPrev = indJourPrev * np.array(weights)[:1+len(weights)-horizonPrev]\n",
    "        weightsPrev = np.nan_to_num(weightsPrev) #permet de remplacer les éventuels Nan par 0 (nécéssaire pour l'échantillonnage)\n",
    "        weightsPrev = pd.DataFrame(weightsPrev)\n",
    "        # Normalisation des poids :\n",
    "        s = np.sum(weightsPrev , axis = 0)\n",
    "        Sim = weightsPrev / s\n",
    "        # Calcul de la prévision : \n",
    "        histoMod_CR = (np.array(histoMod['PAX'][tailleBlocs-1+horizonPrev:]).reshape(-1,1) - np.array(Stats['Mean'][ : - horizonPrev]).reshape(-1,1)) / np.array(Stats['Stds'][ : - horizonPrev]).reshape(-1,1)\n",
    "        histoMod_RS = histoMod_CR * np.array(Stats['Stds'])[-1].reshape(-1,1) + np.array(Stats['Mean'])[-1].reshape(-1,1)\n",
    "        UnePrev =  np.sum(histoMod_RS*np.array(Sim))  \n",
    "        # si ic != 0 : calcul d'un intervalle de confiance par méthode bootstrap :\n",
    "        if ic != 0 :\n",
    "            # Tirage aléatoire avec remise en prenant pour probas : weightsPrev\n",
    "            B = 1000 #Taille de l'échantillon Bootstrap\n",
    "            \n",
    "            echantillon = np.random.choice(histoMod_CR.reshape(1,-1)[0], size = B, replace = True, p=np.array(Sim).reshape(1,-1)[0]) \n",
    "            echantillon = echantillon * np.array(Stats['Stds'])[-1].reshape(1,-1)[0] + np.array(Stats['Mean'])[-1].reshape(1,-1)[0]\n",
    "            residus = echantillon - UnePrev\n",
    "            \n",
    "            # On prend ensuite simplement les quantiles de l'échantillon des résidus simulé par bootstrap\n",
    "            p_l = ((1 - ic)/2) * 100\n",
    "            lower = np.percentile(residus, p_l)\n",
    "            p_u = ((1 + ic)/2) * 100\n",
    "            upper = np.percentile(residus, p_u)\n",
    "            \n",
    "            # Ajout de la prévision et de son intervalle de confiance à la table finale :\n",
    "            UnePrev = pd.DataFrame(data={\"PAX_NP\" : [UnePrev], 'IC'+str(int(ic*100))+'_low_NP' : [UnePrev+lower] ,'IC'+str(int(ic*100))+'_up_NP' : [UnePrev+upper]})\n",
    "            PrevisionsNP = pd.concat([PrevisionsNP , pd.concat([UnePrev , pd.DataFrame([datePrev]) , pd.DataFrame(histoMod[[\"ArrDep\" , \"Faisceau\"]]).head(1).reset_index().drop(columns = ['index'])] , axis = 1)])\n",
    "        \n",
    "        else : \n",
    "            # Ajout de la prévision à la table finale, valeur 0 dans les IC :\n",
    "            UnePrev = pd.DataFrame(data={\"PAX_NP\" : [UnePrev], 'IC'+str(int(ic*100))+'_low_NP' : [0] ,'IC'+str(int(ic*100))+'_up_NP' : [0]})\n",
    "            PrevisionsNP = pd.concat([PrevisionsNP , pd.concat([UnePrev , pd.DataFrame([datePrev]) , pd.DataFrame(histoMod[[\"ArrDep\" , \"Faisceau\"]]).head(1).reset_index().drop(columns = ['index'])] , axis = 1)])\n",
    "    return PrevisionsNP.rename(columns = {0 : \"Date\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse (serie1 , serie2) :\n",
    "    rmse = 0 \n",
    "    n = len(serie1)\n",
    "    for i in range(n) :\n",
    "        rmse += (serie1[i]-serie2[i])**2    \n",
    "    return math.sqrt(rmse/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meilleur_h (histoMod, Calendrier, dateFinMod, hPrev, tailleBlocs) :\n",
    "    \"\"\"\n",
    "    Fonction qui recherche le meilleur h : \n",
    "        - sélectionne des périodes de test : périodes présentes dans l'histo, commençant aux mêmes dates \n",
    "            que la période à prédire, mais pour des années antérieures (de sorte qu'il y ait toujours au moins un an de dispo dans l'histo)\n",
    "        - pour chaque période de test, cherche le meilleur h parmi les différents candidats choisis arbitrairement : \n",
    "            [5,10,15,20,25,30,35,40,45,50]\n",
    "        - prend la moyenne des meilleurs h sélectionnés à l'étape précédente \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    histoMod, Calendrier, dateFinMod, hPrev, tailleBlocs : \n",
    "        idem que dans la fonction previsions_NP et previsions_NP_h_fixe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    h : int\n",
    "        Meilleur h qui permet de faire les meilleurs prédictions\n",
    "\n",
    "    \"\"\"\n",
    "    candidats_h = [i for i in range(5,55,5)]\n",
    "    \n",
    "    meilleurs_h = [] # Liste qui contiendra les meilleurs h retenus pour chaque période testée\n",
    "    \n",
    "    nb = len(histoMod)//365 - 1  # Nombre de périodes testées\n",
    "    \n",
    "    for i in range(1,nb) : \n",
    "\n",
    "        # On choisit d'essayer de prédire la même période k années avant :\n",
    "        dateFinMod2 = dateFinMod - timedelta(days=i*365) \n",
    "        \n",
    "        histoMod2 = histoMod[histoMod['Date']<=dateFinMod2]\n",
    "        infosBlocs2 = infos_blocs (histoMod2,tailleBlocs)\n",
    "        \n",
    "        realise =  histoMod[(histoMod['Date']>dateFinMod2)&(histoMod['Date']<=dateFinMod2+timedelta(days=hPrev))]\n",
    "        realise = list(realise['PAX'])\n",
    "    \n",
    "        # Test de chacun des candidats h, et choix de celui avec la plus petite erreur RMSE :\n",
    "    \n",
    "        meilleur_h = candidats_h[0]        \n",
    "        previsions = previsions_NP_h_fixe (histoMod2, Calendrier, dateFinMod2, infosBlocs2 , hPrev, meilleur_h, 0, tailleBlocs) \n",
    "        meilleure_erreur = rmse(realise, list(previsions['PAX_NP']))\n",
    "    \n",
    "        for k in range(1,len(candidats_h)) :\n",
    "            h = candidats_h[k]\n",
    "            previsions = previsions_NP_h_fixe (histoMod2, Calendrier, dateFinMod2, infosBlocs2 , hPrev, h, 0, tailleBlocs) \n",
    "            erreur = rmse(realise, list(previsions['PAX_NP']))\n",
    "        \n",
    "            if erreur < meilleure_erreur :\n",
    "                meilleur_h = h\n",
    "                meilleure_erreur = erreur\n",
    "        meilleurs_h.append(meilleur_h)\n",
    "        \n",
    "    # print(histoMod2['Faisceau'][0],histoMod2['ArrDep'][0],hPrev,sum(meilleurs_h)/len(meilleurs_h))\n",
    "    return sum(meilleurs_h)/len(meilleurs_h) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def previsions_NP (histoMod, Calendrier, dateDebMod, dateFinMod, hPrev, ic = 0.95, tailleBlocs = 365, gridsearch= False ) :\n",
    "    \"\"\"\n",
    "    Fonction qui réalise les prédictions selon le modèle non-paramètrique \n",
    "    à partir de l'historique donné (déjà filtré pour un faisceau et un type de mouvement),\n",
    "    en choisissant le meilleur hyper paramètre h par cross validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    histoMod : DataFrame\n",
    "        Historique du trafic journalier, sur un seul faisceau et un seul type de mouvement, contenant : 'ArrDep', 'Faisceau', 'Date', 'PAX'\n",
    "    Calendrier : DataFrame\n",
    "        Calendrier à utiliser pour déterminer les groupes de blocs\n",
    "    dateDebMod : datetime64[ns]\n",
    "        Date de début de l'historique\n",
    "    dateFinMod : datetime64[ns]\n",
    "        Date de fin de l'historique\n",
    "    hPrev : int\n",
    "        Nombre de jours pour lesquels faire une prédiction du trafic\n",
    "    tailleBlocs : int, optional\n",
    "        Taille des blocs du modèle. The default is 365 days. \n",
    "    ic : float, optional\n",
    "        Correspond au seuil de l'intervalle de confiance souhaité (mettre 0 pour ne pas calculer d'intervalle de confiance). The default is 0.95.\n",
    "    gridsearch : boolean, optional\n",
    "        Option de recherche des paramètres (h, tailleBlocs), si gridsearch est True, la prévision utilise une méthode de gridsearch, sinon on utilise une méthode de calcul sur h. The default is False. \n",
    "    Returns\n",
    "    -------\n",
    "    PrevisionsNP : DataFrame\n",
    "        Prévisions journalières du modèle (contient 'PAX_NP', 'Date', 'Faisceau', 'ArrDep') + intervalle de confiance 'IC_ic_inf_NP' et 'IC_ic_sup_NP' si ic != 0\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sélection colonnes intérêt Calendrier + dans les colonnes Pont_LunF, .., Pont_VenF, on remplace par 0 si c'est les vacances en même temps\n",
    "    colonnesCalendrier = [\"Date\" , \"Mois\" , \"JourSem\" , \"Semaine\" , \"Semaine_Perso\" , \"Pont_LunF\" , \"Pont_MarF\" , \n",
    "                              \"Pont_Mer1F\" , \"Pont_Mer2F\" , \"Pont_JeuF\" , \"Pont_VenF\" ,\"Pont_SamF\" , \"Pont_DimF\" , \"Vac_Toussaint\" , \"Vac_Noel\" ,\n",
    "                              \"Vac_Hiver_A\" , \"Vac_Hiver_B\" , \"Vac_Hiver_C\" ,\"Vac_Printemps_A\" , \"Vac_Printemps_B\" , \"Vac_Printemps_C\" ,\"Vac_Ete\"]\n",
    "    Calendrier = np.array(Calendrier[colonnesCalendrier])\n",
    "    vacances = Calendrier[:,13:].sum(axis=1) == 0 #Contient True si on n'est pas en vacances et False si on est en vacances\n",
    "    for i in range(5,11) :\n",
    "        Calendrier[:,i] *= vacances\n",
    "    Calendrier = pd.DataFrame(Calendrier, columns=colonnesCalendrier)\n",
    "    \n",
    "    \n",
    "    # Augmentation de l'historique avec le calendrier : \n",
    "    histoMod = pd.merge(histoMod, Calendrier, left_on = ['Date'], right_on = ['Date'], how = 'left')\n",
    "    histoMod = histoMod.sort_values(by='Date')\n",
    "    \n",
    "    \n",
    "    # Choix de la meilleure largeur de la fenêtre : on fait appel à une recherche de type cross validation\n",
    "    if not gridsearch :\n",
    "        # Création des blocs et des informations utiles :\n",
    "        infosBlocs = infos_blocs (histoMod,tailleBlocs)\n",
    "        h = meilleur_h (histoMod, Calendrier, dateFinMod, hPrev, tailleBlocs) \n",
    "        # Réalisation des prévisions avec le h par meilleur h :\n",
    "        PrevisionsNP = previsions_NP_h_fixe (histoMod, Calendrier, dateFinMod, infosBlocs , hPrev, h, ic, tailleBlocs)\n",
    "        \n",
    "    else :\n",
    "        (h, tBlocs) = gridsearch_cv (histoMod, Calendrier, dateFinMod, hPrev) \n",
    "        infosBlocs = infos_blocs (histoMod,tBlocs)\n",
    "        # Réalisation des prévisions avec le h par gridsearch cv :\n",
    "        PrevisionsNP = previsions_NP_h_fixe (histoMod, Calendrier, dateFinMod, infosBlocs , hPrev, h, ic, tBlocs)\n",
    "\n",
    "\n",
    "\n",
    "    return PrevisionsNP\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateDebMod = pd.to_datetime(\"2008-01-01\")\n",
    "dateFinMod = pd.to_datetime(\"2015-12-31\")\n",
    "\n",
    "path = \"/Users/h2jw/Documents/GitHub/StatApp_2020/\"\n",
    "hPrev = 7\n",
    "ic = 0.95   # Seuil de l'intervalle de confiance souhaité\n",
    "database = pd.read_csv(\"/Users/h2jw/Downloads/database_sieges.csv\",low_memory=False,decimal=',')\n",
    "database = database.astype({'Date': 'datetime64[ns]','PAX_FQM':'float','Sièges Corrections_ICI':'float','Coeff_Rempl':'float','Coeff_Rempl_FQM':'float'})\n",
    "database = database.groupby(['Date','Faisceau','ArrDep']).agg({'PAX':'sum','PAX_FQM':'sum','Sièges Corrections_ICI':'sum','Coeff_Rempl':'mean','Coeff_Rempl_FQM':'mean'}).reset_index()\n",
    "Calendrier = pd.read_csv(path+\"Data/Calendrier/Calendrier.csv\", dayfirst = True , sep = ';' , parse_dates = ['Date'])\n",
    "\n",
    "histoMod = database[(database['Date']>=dateDebMod) & (database['Date']<=dateFinMod)]\n",
    "histoPrev = database[(database['Date']>=dateDebMod) & (database['Date']<=dateFinMod+timedelta(days = hPrev))]\n",
    "        # ( sans historique précédent : histoPrev = database[(database['Date']>dateFinMod) & (database['Date']<=dateFinMod+timedelta(days = hPrev))]   )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Faisceau</th>\n",
       "      <th>ArrDep</th>\n",
       "      <th>PAX</th>\n",
       "      <th>PAX_FQM</th>\n",
       "      <th>Sièges Corrections_ICI</th>\n",
       "      <th>Coeff_Rempl</th>\n",
       "      <th>Coeff_Rempl_FQM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>Autre UE</td>\n",
       "      <td>Arrivée</td>\n",
       "      <td>242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>296.205128</td>\n",
       "      <td>0.817001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>Autre UE</td>\n",
       "      <td>Départ</td>\n",
       "      <td>267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>391.237671</td>\n",
       "      <td>0.663779</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>Dom Tom</td>\n",
       "      <td>Arrivée</td>\n",
       "      <td>4122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4371.843733</td>\n",
       "      <td>0.956682</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>Dom Tom</td>\n",
       "      <td>Départ</td>\n",
       "      <td>2730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4903.660937</td>\n",
       "      <td>0.585989</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>International</td>\n",
       "      <td>Arrivée</td>\n",
       "      <td>8323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9600.446843</td>\n",
       "      <td>0.855056</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date       Faisceau   ArrDep   PAX  PAX_FQM  Sièges Corrections_ICI  \\\n",
       "0 2008-01-01       Autre UE  Arrivée   242      0.0              296.205128   \n",
       "1 2008-01-01       Autre UE   Départ   267      0.0              391.237671   \n",
       "2 2008-01-01        Dom Tom  Arrivée  4122      0.0             4371.843733   \n",
       "3 2008-01-01        Dom Tom   Départ  2730      0.0             4903.660937   \n",
       "4 2008-01-01  International  Arrivée  8323      0.0             9600.446843   \n",
       "\n",
       "   Coeff_Rempl  Coeff_Rempl_FQM  \n",
       "0     0.817001              NaN  \n",
       "1     0.663779              NaN  \n",
       "2     0.956682              NaN  \n",
       "3     0.585989              NaN  \n",
       "4     0.855056              NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histoMod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Annee</th>\n",
       "      <th>Mois</th>\n",
       "      <th>Jour</th>\n",
       "      <th>JourSem</th>\n",
       "      <th>Semaine</th>\n",
       "      <th>Diff</th>\n",
       "      <th>Semaine_Perso</th>\n",
       "      <th>JourAn</th>\n",
       "      <th>Noel</th>\n",
       "      <th>...</th>\n",
       "      <th>Pont_DimF</th>\n",
       "      <th>Vac_Toussaint</th>\n",
       "      <th>Vac_Noel</th>\n",
       "      <th>Vac_Hiver_A</th>\n",
       "      <th>Vac_Hiver_B</th>\n",
       "      <th>Vac_Hiver_C</th>\n",
       "      <th>Vac_Printemps_A</th>\n",
       "      <th>Vac_Printemps_B</th>\n",
       "      <th>Vac_Printemps_C</th>\n",
       "      <th>Vac_Ete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-01-02</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-01-03</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-01-04</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-01-05</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Annee  Mois  Jour  JourSem  Semaine  Diff  Semaine_Perso  \\\n",
       "0 2007-01-01   2007     1     1        1        1     1              0   \n",
       "1 2007-01-02   2007     1     2        2        1     1              0   \n",
       "2 2007-01-03   2007     1     3        3        1     1              0   \n",
       "3 2007-01-04   2007     1     4        4        1     1              0   \n",
       "4 2007-01-05   2007     1     5        5        1     1              0   \n",
       "\n",
       "   JourAn  Noel  ...  Pont_DimF  Vac_Toussaint  Vac_Noel  Vac_Hiver_A  \\\n",
       "0       1     0  ...        0.0              0         0            0   \n",
       "1       0     0  ...        0.0              0         0            0   \n",
       "2       0     0  ...        0.0              0         0            0   \n",
       "3       0     0  ...        0.0              0         0            0   \n",
       "4       0     0  ...        0.0              0         0            0   \n",
       "\n",
       "   Vac_Hiver_B  Vac_Hiver_C  Vac_Printemps_A  Vac_Printemps_B  \\\n",
       "0            0            0                0                0   \n",
       "1            0            0                0                0   \n",
       "2            0            0                0                0   \n",
       "3            0            0                0                0   \n",
       "4            0            0                0                0   \n",
       "\n",
       "   Vac_Printemps_C  Vac_Ete  \n",
       "0                0        0  \n",
       "1                0        0  \n",
       "2                0        0  \n",
       "3                0        0  \n",
       "4                0        0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Calendrier.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illustration TimeSeriesSplit\n",
    "Source : https://medium.com/@soumyachess1496/cross-validation-in-time-series-566ae4981ce4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeSeriesSplit(max_train_size=None, n_splits=5)\n",
      "TRAIN: [0] TEST: [1]\n",
      "TRAIN: [0 1] TEST: [2]\n",
      "TRAIN: [0 1 2] TEST: [3]\n",
      "TRAIN: [0 1 2 3] TEST: [4]\n",
      "TRAIN: [0 1 2 3 4] TEST: [5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([1, 2, 3, 4, 5, 6])\n",
    "tscv = TimeSeriesSplit()\n",
    "print(tscv)\n",
    "TimeSeriesSplit(max_train_size=None, n_splits=3)\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index) \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2 ... 5806 5807 5808] [ 5809  5810  5811 ... 11615 11616 11617]\n",
      "[    0     1     2 ... 11615 11616 11617] [11618 11619 11620 ... 17424 17425 17426]\n",
      "[    0     1     2 ... 17424 17425 17426] [17427 17428 17429 ... 23233 23234 23235]\n",
      "[    0     1     2 ... 23233 23234 23235] [23236 23237 23238 ... 29042 29043 29044]\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits = 4)\n",
    "rmse = []\n",
    "for train_index, test_index in tscv.split(histoMod):\n",
    "    cv_train, cv_test = histoMod.iloc[train_index], histoMod.iloc[test_index]\n",
    "    print(train_index, test_index)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illustration Nested TS CV\n",
    "Source : https://www.angioi.com/time-nested-cv-with-sklearn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-01    0\n",
      "2018-01-02    2\n",
      "2018-01-03    4\n",
      "2018-01-04    3\n",
      "2018-01-05    2\n",
      "             ..\n",
      "2018-05-22    0\n",
      "2018-05-23    2\n",
      "2018-05-24    3\n",
      "2018-05-25    4\n",
      "2018-05-26    4\n",
      "Freq: D, Name: X, Length: 146, dtype: int64 \n",
      " y \n",
      " 2018-05-27    4\n",
      "2018-05-28    3\n",
      "2018-05-29    2\n",
      "Freq: D, Name: y, dtype: int64\n",
      "2018-01-01    0\n",
      "2018-01-02    2\n",
      "2018-01-03    4\n",
      "2018-01-04    3\n",
      "2018-01-05    2\n",
      "             ..\n",
      "2018-08-03    1\n",
      "2018-08-04    3\n",
      "2018-08-05    4\n",
      "2018-08-06    2\n",
      "2018-08-07    4\n",
      "Freq: D, Name: X, Length: 219, dtype: int64 \n",
      " y \n",
      " 2018-08-08    0\n",
      "2018-08-09    4\n",
      "2018-08-10    0\n",
      "Freq: D, Name: y, dtype: int64\n",
      "2018-01-01    0\n",
      "2018-01-02    2\n",
      "2018-01-03    4\n",
      "2018-01-04    3\n",
      "2018-01-05    2\n",
      "             ..\n",
      "2018-10-15    4\n",
      "2018-10-16    3\n",
      "2018-10-17    3\n",
      "2018-10-18    0\n",
      "2018-10-19    2\n",
      "Freq: D, Name: X, Length: 292, dtype: int64 \n",
      " y \n",
      " 2018-10-20    2\n",
      "2018-10-21    4\n",
      "2018-10-22    2\n",
      "Freq: D, Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "nRows = 365\n",
    "\n",
    "df = pd.DataFrame(np.random.randint(0,5,size=(nRows, 2)), \n",
    "                  columns = [\"X\",\"y\"], \n",
    "                  index=pd.date_range(\"20180101\", periods=nRows))\n",
    "\n",
    "    \n",
    "n_splits = 3 #Number of train/cv/test folds\n",
    "\n",
    "trainTestSplit = TimeSeriesSplit(n_splits+1).split(df)\n",
    "next(trainTestSplit) #Skip the first fold\n",
    "\n",
    "for trainCvIndices, testIndices in trainTestSplit:\n",
    "    # First, we split Train + CV and Test\n",
    "    XTrainCv, yTrainCv = df.iloc[trainCvIndices,0], df.iloc[[i for i in  range(len(trainCvIndices),len(trainCvIndices)+3)],1]\n",
    "    XTest, yTest       = df.iloc[testIndices,0]   , df.iloc[testIndices,1]\n",
    "    print(XTrainCv,'\\n', 'y', '\\n', yTrainCv)\n",
    "    \n",
    "    # Then, we build a list of the form [ ( [...Train Indices...], [...CV Indices...]  )]\n",
    "    testLength = len(XTest)\n",
    "    trainCvSplit = [(list(range(trainCvIndices[0],trainCvIndices[-testLength])),\n",
    "                     list(range(trainCvIndices[-testLength],trainCvIndices[-1]+1)))]\n",
    "    \n",
    "    # Printing date ranges\n",
    "   # print(\"Training:\"           , XTrainCv.index[0].date(), \"--\", XTrainCv.index[-testLength-1].date(),\n",
    "    #      \", Cv:\"     , XTrainCv.index[-testLength].date(), \"--\", XTrainCv.index[-1].date(),\n",
    "     #     \", Test:\"                , XTest.index[0].date(), \"--\", XTest.index[-1].date())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " On va utiliser cette dernière méthode pour le gridsearch avec cross validation. On dispose alors de training set, validation set et de set de tests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implémentation Gridsearch avec CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch_cv(histoMod, Calendrier, dateFinMod, hPrev):\n",
    "    # En divise l'histoMod à l'aide de la CV k-fold \n",
    "    rmse, best_param = [],[]\n",
    "    n_splits = 3 # Nombre de folds : ici CV 3-fold\n",
    "\n",
    "    trainTestSplit = TimeSeriesSplit(n_splits+1).split(histoMod)\n",
    "    next(trainTestSplit) #on \"zappe\" la première couche\n",
    "\n",
    "    for trainCvIndices, testIndices in trainTestSplit:\n",
    "        # On sépare Train + CV et Test\n",
    "        \n",
    "        XTrainCv, yTrainCv = histoMod.iloc[trainCvIndices], histoMod.iloc[[i for i in range(len(trainCvIndices), len(trainCvIndices)+hPrev)]]\n",
    "        XTest, yTest       = histoMod.iloc[testIndices]   , histoMod.iloc[[i for i in range(len(testIndices), len(testIndices)+hPrev)]]\n",
    "        \n",
    "        # On sépare train et validation\n",
    "        Xtrain, ytrain = XTrainCv.index[:-hPrev-1] , yTrainCv[:-hPrev-1]\n",
    "        Xvalid, yvalid = XTrainCv.index[-hPrev:-1], yTrainCv[-hPrev:-1]\n",
    "        \n",
    "        # on applique le gridsearch simple sur nos ensembles d'entraînement et de validation\n",
    "        gr_se = gridsearch_h(Xtrain, Xvalid, ytrain, yvalid, histoMod, Calendrier, dateFinMod, hPrev)\n",
    "        rmse.append(gr_se[2])\n",
    "        best_param.append((gr_se[0],gr_se[1]))\n",
    "                          \n",
    "                          \n",
    "    # on choisit le tuple minimisant la rmse \n",
    "    return best_param.index(min(rmse))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch_h (X_train, X_valid, Y_train, Y_valid, histoMod, Calendrier, dateFinMod, hPrev):    \n",
    "    rmse = []\n",
    "    \n",
    "    # liste de h    \n",
    "    h_choix = [i for i in range(5,55,5)]\n",
    "\n",
    "    # liste de taillesBlocs \n",
    "    tB_choix = [ 7, 31, 91, 365] # blocs de 7 jours, 1 mois, 3 mois et 1 an\n",
    "\n",
    "    # combinaisons taillesBlocs et h possibles\n",
    "\n",
    "    parametres = []    \n",
    "    for i in h_choix :        \n",
    "        for j in tb_choix :            \n",
    "            parametres.append( ( i, j ) )\n",
    "\n",
    "    print(\"Combinaisons h et tailleBlocs : \",  parameters )\n",
    "\n",
    "    # Recherche dans la liste des combinaisons la solution qui minimise la rmse sur l'ensemble\n",
    "    # de crossvalidation \n",
    "\n",
    "    for k in range( len( parametres ) ) :\n",
    "        infosBlocs = infos_blocs(histoMod, parametres[k][1])\n",
    "        # prévisions sur la période de validation\n",
    "        previsions = previsions_NP_h_fixe (X_train, Calendrier, dateFinMod, infosBlocs, len(X_valid), parametres[k][0], ic = 0, parametres[k][1]) \n",
    "        \n",
    "        rmse.append(rmse(previsions, Y_valid)) \n",
    "\n",
    "\n",
    "\n",
    "    print( \"Maximum accuracy achieved by our model through grid searching : \", max_accuracy )\n",
    "    \n",
    "    return (besth, besttB, rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Faisceau</th>\n",
       "      <th>ArrDep</th>\n",
       "      <th>PAX</th>\n",
       "      <th>PAX_FQM</th>\n",
       "      <th>Sièges Corrections_ICI</th>\n",
       "      <th>Coeff_Rempl</th>\n",
       "      <th>Coeff_Rempl_FQM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>Autre UE</td>\n",
       "      <td>Arrivée</td>\n",
       "      <td>242</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>296.205128</td>\n",
       "      <td>0.817001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>Autre UE</td>\n",
       "      <td>Départ</td>\n",
       "      <td>267</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>391.237671</td>\n",
       "      <td>0.663779</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>Dom Tom</td>\n",
       "      <td>Arrivée</td>\n",
       "      <td>4122</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4371.843733</td>\n",
       "      <td>0.956682</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>Dom Tom</td>\n",
       "      <td>Départ</td>\n",
       "      <td>2730</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4903.660937</td>\n",
       "      <td>0.585989</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>International</td>\n",
       "      <td>Arrivée</td>\n",
       "      <td>8323</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9600.446843</td>\n",
       "      <td>0.855056</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29110</th>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>International</td>\n",
       "      <td>Départ</td>\n",
       "      <td>6299</td>\n",
       "      <td>6086.9600</td>\n",
       "      <td>9694.338182</td>\n",
       "      <td>0.633927</td>\n",
       "      <td>0.641104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29111</th>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>National</td>\n",
       "      <td>Arrivée</td>\n",
       "      <td>12587</td>\n",
       "      <td>12765.9340</td>\n",
       "      <td>19414.918018</td>\n",
       "      <td>0.640150</td>\n",
       "      <td>0.672464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29112</th>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>National</td>\n",
       "      <td>Départ</td>\n",
       "      <td>12167</td>\n",
       "      <td>12771.8428</td>\n",
       "      <td>18560.761829</td>\n",
       "      <td>0.628015</td>\n",
       "      <td>0.679218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29113</th>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>Schengen</td>\n",
       "      <td>Arrivée</td>\n",
       "      <td>9319</td>\n",
       "      <td>9042.8350</td>\n",
       "      <td>12280.332661</td>\n",
       "      <td>0.754476</td>\n",
       "      <td>0.732397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29114</th>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>Schengen</td>\n",
       "      <td>Départ</td>\n",
       "      <td>8301</td>\n",
       "      <td>8193.8800</td>\n",
       "      <td>12393.912596</td>\n",
       "      <td>0.665359</td>\n",
       "      <td>0.655000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29115 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date       Faisceau   ArrDep    PAX     PAX_FQM  \\\n",
       "0     2008-01-01       Autre UE  Arrivée    242      0.0000   \n",
       "1     2008-01-01       Autre UE   Départ    267      0.0000   \n",
       "2     2008-01-01        Dom Tom  Arrivée   4122      0.0000   \n",
       "3     2008-01-01        Dom Tom   Départ   2730      0.0000   \n",
       "4     2008-01-01  International  Arrivée   8323      0.0000   \n",
       "...          ...            ...      ...    ...         ...   \n",
       "29110 2016-01-07  International   Départ   6299   6086.9600   \n",
       "29111 2016-01-07       National  Arrivée  12587  12765.9340   \n",
       "29112 2016-01-07       National   Départ  12167  12771.8428   \n",
       "29113 2016-01-07       Schengen  Arrivée   9319   9042.8350   \n",
       "29114 2016-01-07       Schengen   Départ   8301   8193.8800   \n",
       "\n",
       "       Sièges Corrections_ICI  Coeff_Rempl  Coeff_Rempl_FQM  \n",
       "0                  296.205128     0.817001              NaN  \n",
       "1                  391.237671     0.663779              NaN  \n",
       "2                 4371.843733     0.956682              NaN  \n",
       "3                 4903.660937     0.585989              NaN  \n",
       "4                 9600.446843     0.855056              NaN  \n",
       "...                       ...          ...              ...  \n",
       "29110             9694.338182     0.633927         0.641104  \n",
       "29111            19414.918018     0.640150         0.672464  \n",
       "29112            18560.761829     0.628015         0.679218  \n",
       "29113            12280.332661     0.754476         0.732397  \n",
       "29114            12393.912596     0.665359         0.655000  \n",
       "\n",
       "[29115 rows x 8 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histoPrev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
